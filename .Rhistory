summary(denim.mod1)
pmaxFratio( 9.451,9,9,lower.tail = F)#n is replicates per tx
sqrt(76.3)
resid(denim.mod1)
plot(resid(denim.mod1),Edge_score)
plot(resid(denim.mod1)~Edge_score)
re=rstandard(denim.mod1)
plot(re~Edge_score)
halo <- read.table("http://www.stat.ufl.edu/~winner/data/halo1.dat",
header=F, col.names=c("essayqual","picture","grade"))
attach(halo)
essayqual <- factor(essayqual)
picture <- factor(picture)
interaction.plot(essayqual,picture,grade)
View(halo)
denim_abrasion=read.table("http://stat.ufl.edu/~winner/data/denim_abrasion.dat",col.names =
c("Laundry_cycles","Denim_tx","Edge_score"))
attach(denim_abrasion);names(denim_abrasion)
interaction.plot(Denim_tx,Edge_score,Laundry_cycles)
Denim_tx
interaction.plot(essayqual,picture,grade)
interaction.plot(Denim_tx,Laundry_cycles,Edge_score,
)
halo.mod1 <- aov(grade ~ essayqual + picture)
anova(halo.mod1)
summary.lm(halo.mod1)
denim.mod1=aov(Edge_score~Laundry_cycles+Denim_tx+Laundry_cycles*Denim_tx)
summary(denim.mod1)
Laundry_cycles=factor(Laundry_cycles)
Denim_tx=factor(Denim_tx)
denim_abrasion=read.table("http://stat.ufl.edu/~winner/data/denim_abrasion.dat",col.names =
c("Laundry_cycles","Denim_tx","Edge_score"))
View(denim_abrasion)
attach(denim_abrasion);names(denim_abrasion)
Laundry_cycles=factor(Laundry_cycles)
Denim_tx=factor(Denim_tx)
denim.mod1=aov(Edge_score~Laundry_cycles+Denim_tx+Laundry_cycles*Denim_tx)
summary(denim.mod1)
summary.lm(denim.mod1)
Denim_tx
summary(denim.mod1)
interaction.plot(Denim_tx,Laundry_cycles,Edge_score)
plot(resid(denim.mod1)~Edge_score)
denim.mod1
summary.lm(denim.mod1)
length(Edge_score)#nT is 90
plot(resid(denim.mod1)~fitted.values(denim.mod1))
re=rstandard(denim.mod1)
plot(re~fitted.values(denim.mod1))
fitted.values(denim.mod1)
plot(resid(denim.mod1)~fitted.values(denim.mod1))
qTukey(.95,4,238)
qtukey(.95,4,328)
qtukey(.95,8,328)
#Tukey's tests
#test 1: Cycle 0 vs Cycle 5 mean
#2.69 vs 2.33
length(Edge_score)
qtukey(.95,3,81)
(q=qtukey(.95,3,81))
#Tukey's tests
#test 1: Cycle 0 vs Cycle 5 mean
#2.69 vs 2.33
(nT=length(Edge_score))
sqrt(3159/4*((1/41+1/45)+(1/36+1/45)))
sqrt(3159/4*((1/41+1/45)-(1/36+1/45)))
#Tukey's tests
#test 1: Cycle 0 vs Cycle 5 mean
#2.69 vs 2.33
a=3
b=3
length(Edge_score[Laundry_cycles==1&Denim_tx==1]))
length(Edge_score[Laundry_cycles==1&Denim_tx==1])
length(Edge_score[Laundry_cycles==1&Denim_tx==2])
length(Edge_score[Laundry_cycles==1&Denim_tx==3])
length(Edge_score[Laundry_cycles==2&Denim_tx==3])
length(Edge_score[Laundry_cycles==3&Denim_tx==3])
length(Edge_score[Laundry_cycles==3&Denim_tx==1])
length(Edge_score[Laundry_cycles==3&Denim_tx==2])
length(Edge_score[Laundry_cycles==3&Denim_tx==3])
length(Edge_score[Laundry_cycles==2&Denim_tx==3])
length(Edge_score[Laundry_cycles==2&Denim_tx==1])
length(Edge_score[Laundry_cycles==2&Denim_tx==2])
(sL=sqrt(MSE/b^2*((1/10*3)+(1/10*3)))
)
summary(denim.mod1)
MSE=.172
(sL=sqrt(MSE/b^2*((1/10*3)+(1/10*3))))
(q=qtukey(.95,3,81))
q*sL/sqrt(2)
TukeyHSD=q*sL/sqrt(2)
(TukeyHSD=q*sL/sqrt(2))
2.33+TukeyHSD
2.33+TukeyHSD>2.69
source('~/UF/Semester 7/STA4211/Exam2/hw2.R', echo=TRUE)
#Tukey's tests
#test 1: Cycle 0 vs Cycle 5 mean
#2.69 vs 2.33
a=3
b=3
MSE=.172
(nT=length(Edge_score))
(q=qtukey(.95,3,81))
(sL=sqrt(MSE/b^2*((1/10*3)+(1/10*3))))
(TukeyHSD=q*sL/sqrt(2))
2.33+TukeyHSD>2.69
2.69-2.33>TukeyHSD
2.69-2.33>TukeyHSD#If this is true, then the difference exceeds Tukey HSD and is significant
nT-a*b
(q=qtukey(.95,3,nT-a*b))
summary(denim.mod1)
(q=qtukey(.95,q,nT-a*b))
(q=qtukey(.95,a,nT-a*b))
#Test 2: Cycle 5 vs Cycle 25 mean
#2.33-2.17
(q=qtukey(.95,a,nT-a*b))
#Test 2: Cycle 5 vs Cycle 25 mean
#2.33-2.17
2.33-2.17>TukeyHSD#If this is true, then the difference exceeds Tukey HSD and is significant
#Test 3: Cycle 0 vs Cycle 25 mean
#2.69-2.17
2.69-2.17>TukeyHSD#If this is true, then the difference exceeds Tukey HSD and is significant
(TukeyHSD=q*sL/sqrt(2))
#Test 4: Wash Pre vs Stone mean
(q=qtukey(.95,b,nT-a*b))
(sL=sqrt(MSE/a^2*((1/10*3)+(1/10*3))))
(TukeyHSD=q*sL/sqrt(2))
2.86-1.91>TukeyHSD#If this is true, then the difference exceeds Tukey HSD and is significant
#Test 5: Wash Stone vs Enzyme mean
#2.42-1.91
2.42-1.91>TukeyHSD
#Test 6: Wash Pre vs Enzyme mean
#2.86-2.42
2.86-2.42>TukeyHSD
TukeyHSD
#################################################################
#E-reader example
ereader=read.table("http://www.stat.ufl.edu/~winner/data/ereader1.dat",col.names = c("
Device","Lighting_Condition","Reading_Time"))
head(ereader)
#################################################################
#E-reader example
ereader=read.table("http://www.stat.ufl.edu/~winner/data/ereader1.dat",col.names = c(
"Device","Lighting_Condition","Reading_Time"))
head(ereader)
attach(ereader);names(ereader)
#Halo effect example
halo <- read.table("http://www.stat.ufl.edu/~winner/data/halo1.dat",
header=F, col.names=c("essayqual","picture","grade"))
attach(halo)
tapply(grade,list(essayqual,picture),mean)
essayqual
picture
names(halo)
tapply(grade,list(essayqual,picture),mean)
picture
tapply(Reading_Time,Device,Lighting_Condition)
tapply(Reading_Time,list(Device,Lighting_Condition),sd)
tapply(Reading_Time,list(Device,Lighting_Condition),mean)
# length(Edge_score[Laundry_cycles==2&Denim_tx==2])
tapply(Edge_score,Laundry_cycles,Denim_tx)
# length(Edge_score[Laundry_cycles==2&Denim_tx==2])
tapply(Edge_score,list(Laundry_cycles,Denim_tx),mean)
tapply(Reading_Time,list(Device,Lighting_Condition),sd)
#Hartley's test
tapply(Edge_score,list(Laundry_cycles,Denim_tx),mean)
#Hartley's test
(sds=tapply(Edge_score,list(Laundry_cycles,Denim_tx),mean))
sds[1]
sds[2]
sds[1,1]
sds[1,2]
max(sds)
min(sds)
#Hartley's test
(sds=tapply(Edge_score,list(Laundry_cycles,Denim_tx),mean))
(H_star=max(sds^2)/min(sds^2))
qmaxFratio(.95,3,9)
(H=qmaxFratio(.95,3,9))
H_star>H
#Hartley's test
(sds=tapply(Edge_score,list(Laundry_cycles,Denim_tx),mean))
(H_star=max(sds^2)/min(sds^2))
(H=qmaxFratio(.95,3,9))
H_star>H
###################################################################################
abundance=read.table("http://stat.ufl.edu/~winner/data/abundance.dat",col.names = c("Year",
"Location Area","Catch-per-unit area","ln(catch)"))
head(abundance)
View(abundance)
###################################################################################
abundance=read.table("http://stat.ufl.edu/~winner/data/abundance.dat",col.names = c("Year",
"Location Area","Catchperunit_area","lncatch"))
head(abundance)
###################################################################################
abundance=read.table("http://stat.ufl.edu/~winner/data/abundance.dat",col.names = c("Year",
"Location_Area","Catchperunit_area","lncatch"))
head(abundance)
###################################################################################
abundance=read.table("http://stat.ufl.edu/~winner/data/abundance.dat",col.names = c("Year",
"Location_Area","Catchperunit_area","ln_catch"))
head(abundance)
attach(abundance)
names(abundance)
Location_Area=factor(Location_Area)
Year=factor(Year)
(abundance.mod1=aov(ln_catch~Year+Location_Area))
summary(abundance.mod1)
summary.lm(abundance.mod1)
######################################################################
#Karate board analysis
karate=read.table("http://stat.ufl.edu/~winner/sta4211/karate_board1.dat",header=T);head(karate)
attach(karate);names(karate)
View(karate)
Wood=factor(Wood)
Board=factor(Board)
Board
rm(Wood)
Wood
Board
rm(Board)
Board
pdf("C:/Users/Silvio/Documents/UF/Semester 7/STA4211/Exam2.pdf")
Y
names(karate)
kb.mod1=lm(Y~X1 + X2 + X3 + X4 + X1X4 + X2X4 + X3X4)
anova(kb.mod1)
kb.mod2=aov(Y~factor(Wood)+factor(Board)+factor(Wood)*factor(Board))
summary(kb.mod2)
tapply(Y,list(Wood,Board),mean)
# length(Edge_score[Laundry_cycles==2&Denim_tx==2])
denim_means=tapply(Edge_score,list(Laundry_cycles,Denim_tx),mean)
denim_means
rowMeans(denim_means)
denim_means$4=rowMeans(denim_means)
class(denim_means)
as.data.frame(denim_means)
denim_means$4=rowMeans(denim_means)
source('~/UF/Semester 7/STA4211/Exam2/hw2.R', echo=TRUE)
as.data.frame(denim_means)
class(denim_means)
denim_means=as.data.frame(denim_means)
class(denim_means)
denim_means$4=rowMeans(denim_means)
denim_means$"4"=rowMeans(denim_means)
denim_means
# length(Edge_score[Laundry_cycles==2&Denim_tx==2])
denim_means=tapply(Edge_score,list(Laundry_cycles,Denim_tx),mean)
denim_means=as.data.frame(denim_means)
class(denim_means)
denim_means$"Row_Means"=rowMeans(denim_means)
denim_means$"Row_Means"=rowMeans(denim_means);head(denim_means)
rbind(colMeans(denim_means))
rbind(denim_means,colMeans(denim_means))
denim_means
denim_means=rbind(denim_means,colMeans(denim_means))
denim_means
denim_means=tapply(Edge_score,list(Laundry_cycles,Denim_tx),mean)
denim_means=as.data.frame(denim_means)
class(denim_means)
denim_means$"Row_Means"=rowMeans(denim_means);head(denim_means)
denim_means=rbind(denim_means,colMeans(denim_means))
denim_means
row.names.data.frame(c("1","2","3","Column_Means"))
rownames(denim_means,c("1","2","3","Column_Means"))
denim_means
karate_means=tapply(Y,list(Wood,Board),mean)
karate_means=as.data.frame(karate_means)
karate_means$"Row_Means"=rowMeans(karate_means)
karate_means=rbind(karate_means,colMeans(karate_means));head(karate_means)
mean(Y)
mean(Edge_score)
names(karate)
mean(karate$Y)
(H=qmaxFratio(.95,9,9))
biz <- read.table("http://www.stat.ufl.edu/~winner/data/jb42.dat",header=F,
col.names=c("index","year","Y"))
attach(biz)
head(biz)
install.packages("additivityTests")
library(additivityTests)
### biz is sorted by index, then year (stacked COLUMNS from spreadsheet)
(Y.mat <- matrix(Y,byrow=F,ncol=8))
tukey.test(Y.mat)
length(biz$year)
View(biz)
144-35-1
144-6*4-1
min(biz$year)-max(biz$year)
max(index)-min(index)
max(biz$index)-min(biz$index)
tukey.test(Y.mat)
### biz is sorted by index, then year (stacked COLUMNS from spreadsheet)
(Y.mat <- matrix(Y,byrow=F,ncol=8))
tukey.test(Y.mat)
(Y.mat <- matrix(Y,byrow=F,ncol=16))
tukey.test(Y.mat)
### biz is sorted by index, then year (stacked COLUMNS from spreadsheet)
(Y.mat <- matrix(Y,byrow=F,ncol=8))
(Y.mat <- matrix(Y,byrow=F,ncol=18))
tukey.test(Y.mat)
### biz is sorted by index, then year (stacked COLUMNS from spreadsheet)
(Y.mat <- matrix(Y,byrow=F,ncol=8))
(Y.mat <- matrix(Y,byrow=F,ncol=18))
(Y.mat <- matrix(Y,byrow=T,ncol=18))
#CANNOT DO IT THIS WAY, wiTh 18 CoLUMns
tukey.test(Y.mat)
### biz is sorted by index, then year (stacked COLUMNS from spreadsheet)
(Y.mat <- matrix(Y,byrow=F,ncol=8))
names(abundance)
names(biz)
levels(index)
levels(year)
year
factor(year)
#ODOFNA
Location_Area
Year
#ODOFNA
View(abundance)
(catch.mat <- matrix(ln_catch,byrow=F,ncol=6))
### biz is sorted by index, then year (stacked COLUMNS from spreadsheet)
(Y.mat <- matrix(Y,byrow=F,ncol=8))
(catch.mat <- matrix(ln_catch,byrow=F,ncol=6))
tukey.test(catch.mat)
#Can check if correct indexing by looking at level of each factor and see if align with data
#e.g. first column should be all 1965 Y values, good!
tukey.test(Y.mat)
#Karate Means
(a.mean=mean(Edge_score[Wood==1&Board==1]))
(col1.mean=mean(Edge_score[Denim_tx==1]))
(col2.mean=mean(Edge_score[Denim_tx==2]))
(col1.mean=mean(Edge_score[Board==1]))
######################################################################
#Karate board analysis
karate=read.table("http://stat.ufl.edu/~winner/sta4211/karate_board1.dat",header=T);head(karate)
attach(karate);names(karate)
Board=factor(Board)
Wood=factor(Wood)
#Karate Means
(a.mean=mean(Edge_score[Wood==1&Board==1]))
(col1.mean=mean(Edge_score[Board==1]))
Edge_score[Board==1])
Edge_score[Board==1]
View(karate)
#Karate Means
(a.mean=mean(Y[Wood==1&Board==1]))
(col1.mean=mean(Y[Board==1]))
(col2.mean=mean(Y[Board==2]))
(row1.mean=mean(Y[Wood==1]))
(row2.mean=mean(Y[Wood==2]))
(row3.mean=mean(Y[Wood==3]))
(row4.mean=mean(Y[Wood==4]))
karate_means
length(Y[Wood==1&Board==1])
length(Y[Wood==1&Board==2])
#Tukey's tests
#test 1: Cycle 0 vs Cycle 5 mean
#2.69 vs 2.33
a=4
b=2
(nT=length(Y))
mean(Y)
(nT=length(Y))
kb.mod2=aov(Y~factor(Wood)+factor(Board)+factor(Wood)*factor(Board))
summary(kb.mod2)
kb.mod3=aov(Y~factor(Wood)+factor(Board))
summary(kb.mod3)
kb.mod1=lm(Y~X1 + X2 + X3 + X4 + X1X4 + X2X4 + X3X4)
anova(kb.mod1)
kb.mod2 <- lm(Y ~ X1 + X2 + X3 + X4)
anova(kb.mod2)
kb.mod3 <- lm(Y ~  X4 + X1X4 + X2X4 + X3X4)
anova(kb.mod3)
kb.mod4 <- lm(Y ~ X1 + X2 + X3 + X1X4 + X2X4 + X3X4)
anova(kb.mod4)
anova(kb.mod2,kb.mod1)
kb.mod6=aov(Y~factor(Wood)+factor(Board)+factor(Wood)*factor(Board))
summary(kb.mod2)
summary(kb.mod6)
kb.mod5=aov(Y~factor(Wood)+factor(Board))
summary(kb.mod5)
kb.mod5=aov(Y~factor(Wood)+factor(Board))
summary(kb.mod5)
MSE=3134#from summary output above
#Tukey's tests
#test 1:
a=4
b=2
(nT=length(Y))
nT-a*b
(q=qtukey(.95,a,nT-a*b))
kb.mod6=aov(Y~factor(Wood)+factor(Board)+factor(Wood)*factor(Board))
summary(kb.mod6)
MSE=3159#from summary output above
(nT=length(Y))
(q=qtukey(.95,a,nT-a*b))
b
(sL=sqrt(MSE/b^2*((1/41+1/45)+(1/36+1/45))))
(TukeyHSD=q*sL/sqrt(2))
2.5282*8.37
98-91>TukeyHSD#If this is true, then the difference exceeds Tukey HSD and is significant
TukeyHSD
a=4
b=2
MSE=3159#from summary output above
(nT=length(Y))
(q=qtukey(.95,a,nT-a*b))
(sL=sqrt(MSE/b^2*((1/41+1/45)+(1/36+1/45))))
(TukeyHSD=q*sL/sqrt(2))
98-91>TukeyHSD#If this is true, then the difference exceeds Tukey HSD and is significant
#test 2
#98-75
(q=qtukey(.95,a,nT-a*b))
(sL=sqrt(MSE/b^2*((1/41+1/45)+(1/34+1/45))))
(TukeyHSD=q*sL/sqrt(2))
98-75>TukeyHSD#If this is true, then the difference exceeds Tukey HSD and is significant
length(Y[Wood==4&Board==1])
length(Y[Wood==4&Board==2])
#test 3
#98-70
(q=qtukey(.95,a,nT-a*b))
(sL=sqrt(MSE/b^2*((1/41+1/45)+(1/45+1/45))))
(TukeyHSD=q*sL/sqrt(2))
98-70>TukeyHSD#If this is true, then the difference exceeds Tukey HSD and is significant
#test 4
#91-74.5
(sL=sqrt(MSE/b^2*((1/36+1/45)+(1/34+1/45))))
(TukeyHSD=q*sL/sqrt(2))
91-74.5>TukeyHSD#If this is true, then the difference exceeds Tukey HSD and is significant
MSE
#test 5
#91-70
(sL=sqrt(MSE/b^2*((1/36+1/45)+(1/45+1/45))))
(TukeyHSD=q*sL/sqrt(2))
91-74.5>TukeyHSD#If this is true, then the difference exceeds Tukey HSD and is significant
91-70>TukeyHSD#If this is true, then the difference exceeds Tukey HSD and is significant
#test 5
#91-70
(sL=sqrt(MSE/b^2*((1/36+1/45)+(1/45+1/45))))
(TukeyHSD=q*sL/sqrt(2))
91-70>TukeyHSD#If this is true, then the difference exceeds Tukey HSD and is significant
#test 6
#74.5-70
(sL=sqrt(MSE/b^2*((1/34+1/45)+(1/45+1/45))))
(TukeyHSD=q*sL/sqrt(2))
74.5-70>TukeyHSD#If this is true, then the difference exceeds Tukey HSD and is significant
denim_abrasion=read.table("http://stat.ufl.edu/~winner/data/denim_abrasion.dat",col.names =
c("Laundry_cycles","Denim_tx","Edge_score"))
View(denim_abrasion)
attach(denim_abrasion);names(denim_abrasion)
Laundry_cycles=factor(Laundry_cycles)
Denim_tx=factor(Denim_tx)
#Tukey's tests
#test 1: Cycle 0 vs Cycle 5 mean
#2.69 vs 2.33
a=3
b=3
MSE=.172#from summary output above
(nT=length(Edge_score))
(q=qtukey(.95,a,nT-a*b))
#Bonferroni tests
g=a*b*(a*b-1)/2;g
g
1-.05/(2*g)
nT-a*b
#test 1
q=qt(1-.05/(2*g),nT-a*b);q
(sL=sqrt(MSE/b^2*((1/10*3)+(1/10*3))))
b^2
(BonferroniHSD=q*sL/sqrt(2))
q=qt(1-.05/(2*g),nT-a*b);q
(sL=sqrt(MSE/b^2*((1/10*3)+(1/10*3))))
(BonferroniHSD=q*sL/sqrt(2))
2.69-2.33>BonferroniHSD#If this is true, then the difference exceeds Tukey HSD and is significant
BonferroniHSD
#test 2
2.33-2.17>BonferroniHSD
#tEST 3 bonferroni
#Bonferroni
2.69-2.17>BonferroniHSD
#Test 4 bonferroni
#bonferroni
2.86-1.91>BonferroniHSD
#Test 4 bonferroni
#bonferroni
2.86-1.91>BonferroniHSD
#Test 5
#Bonferroni
2.42-1.91>BonferroniHSD
#Test 6
#Bonferroni
2.86-2.42>BonferroniHSD
4987.46/288
rm(list=ls())
library(cartography)
rootdir="C:/Users/Silvio/Documents/"
mapdir="ArcGIS Explorer/My Basemaps/MEX_adm/"
setwd(paste0(rootdir,"GitHub/U-of-Florida-Yucatan-Project"))
# install.packages("cluster")
library(cluster)
# install.packages("dplyr")
library(dplyr)
#reading files necessary
py=read.table(paste0(rootdir,"R/Yucatan-Project/pop-yucatan/population-yucatan.txt"),header = T)
ly<-read.table(paste0(rootdir,"R/Yucatan-Project/pop-yucatan/locations-yucatan.txt"),header=T)
ly$hid=ly$id
ly$workid=ly$id
py=left_join(py,ly[,c("hid","x","y")],by="hid")#adding 2 columns in py (after workid) with house x y coordinates
py=left_join(py,ly[,c("workid","x","y")],by="workid")
colnames(py)<-c("pid","hid","age","sex","hh_serial","pernum","workid","x1","y1","x2","y2")
head(py)
